<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Claire Labit-Bonis</title><link>http://clairelabitbonis.github.io/fr/</link><description>Recent content on Claire Labit-Bonis</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 04 Nov 2022 10:00:00 +0900</lastBuildDate><atom:link href="http://clairelabitbonis.github.io/fr/index.xml" rel="self" type="application/rss+xml"/><item><title>DLCV-CM-00 | De l'I.A. au deep learning</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/01_why_deep_learning/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/01_why_deep_learning/</guid><description> Objectifs pédagogiques Ce premier cours a pour objectif de répondre aux trois questions suivantes autour du deep learning :
à quoi ça sert ? pourquoi c&amp;rsquo;est techniquement intéressant ? quels en sont les grands principes ?</description></item><item><title>DLCV-CM-01 | Let's learn deeply</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/02_lets_learn_deeply/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/02_lets_learn_deeply/</guid><description/></item><item><title>DLCV-TP-00 | Présentation</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/00_presentation/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/00_presentation/</guid><description>Objectifs pédagogiques L&amp;rsquo;objectif de ces séances de travaux pratiques est de toucher à toutes les étapes de l&amp;rsquo;ingénierie du deep learning, à savoir :
l&amp;rsquo;acquisition et l&amp;rsquo;annotation de données, l&amp;rsquo;apprentissage de réseaux de convolution, l&amp;rsquo;évaluation des performances de la tâche apprise, la visualisation des résultats obtenus. Pour cela, notre point de départ sera le détecteur d&amp;rsquo;objets très largement connu et utilisé par les communautés scientifique mais aussi industrielle : YOLO (You Only Look Once).</description></item><item><title>DLCV-TP-01 | L'union fait la force</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/01_unity_is_strength/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/01_unity_is_strength/</guid><description/></item><item><title>DLCV-TP-10 | YOLO !</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/02_yolo/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/02_yolo/</guid><description/></item><item><title>DLCV-TP-11 | Voyons...</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/03_lets_see/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/03_lets_see/</guid><description/></item><item><title>3DP-TP-00 | Segmentation de nuages de points 3D par capteur à lumière structurée RGB-D avec CloudCompare</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/cc_segmentation/</link><pubDate>Sat, 16 Jul 2022 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/cc_segmentation/</guid><description>Contrôle qualité d&amp;rsquo;objets 3D.</description></item><item><title>3DP-TP-01 | Localisation monoculaire par PnL itérative</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/monocular_localization/</link><pubDate>Sat, 16 Jul 2022 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/monocular_localization/</guid><description>Iterative estimation of a camera extrinsic parameters.</description></item><item><title>Introduction</title><link>http://clairelabitbonis.github.io/fr/posts/introduction/</link><pubDate>Mon, 08 Jun 2020 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/introduction/</guid><description>La versionj en francais</description></item><item><title>Search Results</title><link>http://clairelabitbonis.github.io/fr/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>http://clairelabitbonis.github.io/fr/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item></channel></rss>