<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Enseignements on Claire Labit-Bonis</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/</link><description>Recent content in Enseignements on Claire Labit-Bonis</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 08 Jun 2020 08:06:25 +0600</lastBuildDate><atom:link href="http://clairelabitbonis.github.io/fr/posts/teaching/index.xml" rel="self" type="application/rss+xml"/><item><title>DLCV-CM-00 | De l'I.A. au deep learning</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/01_why_deep_learning/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/01_why_deep_learning/</guid><description> Objectifs pédagogiques Ce premier cours a pour objectif de répondre aux trois questions suivantes autour du deep learning :
à quoi ça sert ? pourquoi c&amp;rsquo;est techniquement intéressant ? quels en sont les grands principes ?</description></item><item><title>DLCV-CM-01 | Let's go deeper</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/02_lets_learn_deeply/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/02_lets_learn_deeply/</guid><description/></item><item><title>DLCV-TP-00 | Présentation</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/00_presentation/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/00_presentation/</guid><description>Objectifs pédagogiques L&amp;rsquo;objectif de ces séances de travaux pratiques est de toucher à toutes les étapes de l&amp;rsquo;ingénierie du deep learning, à savoir :
l&amp;rsquo;acquisition et l&amp;rsquo;annotation de données, l&amp;rsquo;apprentissage de réseaux de convolution, l&amp;rsquo;évaluation des performances de la tâche apprise, la visualisation des résultats obtenus. Pour cela, notre point de départ sera le détecteur d&amp;rsquo;objets très largement connu et utilisé par les communautés scientifique mais aussi industrielle : YOLO (You Only Look Once).</description></item><item><title>3DP-TP-00 | Segmentation de nuages de points 3D par capteur à lumière structurée RGB-D avec CloudCompare</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/cc_segmentation/</link><pubDate>Sat, 16 Jul 2022 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/cc_segmentation/</guid><description>Contrôle qualité d&amp;rsquo;objets 3D.</description></item><item><title>3DP-TP-01 | Localisation monoculaire par PnL itérative</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/monocular_localization/</link><pubDate>Sat, 16 Jul 2022 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/monocular_localization/</guid><description>Iterative estimation of a camera extrinsic parameters.</description></item></channel></rss>