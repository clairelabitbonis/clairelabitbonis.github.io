<!doctype html><html><head><title>Localisation monoculaire par PnL itérative</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0a17c6d8ab77c1c9df3e22d1e0f9b13d_86416_42x0_resize_box_2.png><meta property="og:title" content="Localisation monoculaire par PnL itérative"><meta property="og:description" content="Iterative estimation of a camera extrinsic parameters."><meta property="og:type" content="article"><meta property="og:url" content="http://clairelabitbonis.gitlab.io/fr/posts/teaching/3d_perception/monocular_localization/"><meta property="og:image" content="http://clairelabitbonis.gitlab.io/fr/posts/teaching/3d_perception/monocular_localization/featured.png"><meta property="article:published_time" content="2022-07-16T00:00:00+00:00"><meta property="article:modified_time" content="2022-07-16T00:00:00+00:00"><meta name=description content="Iterative estimation of a camera extrinsic parameters."><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/fr><img src=/images/site/main-logo_hu0a17c6d8ab77c1c9df3e22d1e0f9b13d_86416_42x0_resize_box_2.png alt=Logo>
Claire Labit-Bonis</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="flag-icon flag-icon-fr"></span>Français</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/posts/teaching/3d_perception/monocular_localization><span class="flag-icon flag-icon-gb"></span>English</a></div></li><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu0a17c6d8ab77c1c9df3e22d1e0f9b13d_86416_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu2230ff0c1688347dd01f9a568f627fa9_80011_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/fr/search><input type=text name=keyword placeholder=Chercher data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/fr/posts data-filter=all>Articles</a></li><div class=subtree><li><a href=/fr/posts/introduction/ title=Introduction>Introduction</a></li><li><i class="fas fa-minus-circle"></i><a class=active href=/fr/posts/teaching/>Enseignements</a><ul class=active><li><i class="fas fa-minus-circle"></i><a class=active href=/fr/posts/teaching/3d_perception/>Perception 3D</a><ul class=active><li><a class=active href=/fr/posts/teaching/3d_perception/monocular_localization/ title="Localisation mono.">Localisation mono.</a></li><li><a href=/fr/posts/teaching/3d_perception/cc_segmentation/ title=Segmentation>Segmentation</a></li></ul></li><li><a href=/fr/posts/teaching/logistics/ title=Logistique>Logistique</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/fr/posts/teaching/3d_perception/monocular_localization/featured.png)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/default-avatar_hu9bf48a08e17db6472c2e32b73058a6bb_47653_120x120_fit_box_2.png alt="Author Image"><h5 class=author-name></h5><p>:date_full</p></div><div class=title><h1>Localisation monoculaire par PnL itérative</h1></div><div class=post-content id=post-content><blockquote><p>Cet exercice consiste à remplir des fonctions ou des morceaux vides dans le fichier <code>localisation.py</code> :</p><ul><li><a href=#anchor-step-1>étape 1</a> : <code>perspective_projection</code> et <code>transform_and_draw_model</code>,</li><li><a href=#anchor-step-2>étape 2</a> : <code>calculate_normal_vector</code> et <code>calculate_error</code></li><li><a href=#anchor-step-3>étape 3</a> : <code>partial_derivatives</code>,</li><li><a href=#anchor-step-4>étape 4</a> : transformation vers un deuxième point de vue.</li></ul><p>Chaque fonction et le rôle qu&rsquo;elle remplit sont décrits dans cet article.</p></blockquote><div class="alert alert-danger"><strong>Ne vous jetez pas dans le codage des fonctions dès la partie &ldquo;définition des objectifs&rdquo;, qui n&rsquo;est qu&rsquo;une explication théorique globale pour présenter le sujet. Chaque étape et les fonctions qui qui sont propres sont décrites en détail dans les parties correspondantes : <a href=#anchor-step-1>étape 1</a>, <a href=#anchor-step-2>étape 2</a>, <a href=#anchor-step-3>étape 3</a>, <a href=#anchor-step-4>étape 4</a>.</strong></div><h2 id=anchor-step-0>Définition des objectifs</h2><p>L&rsquo;objectif de cet exercice est de trouver la transformation optimale à appliquer à un modèle 3D exprimé en centimètres dans un repère <em>objet</em> \(\mathcal{R_o} (X,Y,Z)\) (parfois appelé repère <em>monde</em> \(\mathcal{R_w}\)) afin de le dessiner dans une image 2D exprimée en pixels dans un repère <em>image</em> \(\mathcal{R_i} (u,v)\). Le modèle 3D a été téléchargé sur <a href=https://free3d.com>free3d</a> et modifié dans <a href=https://www.blender.org/>Blender</a> pour les besoins de l&rsquo;exercice. Ses points et arêtes ont respectivement été exportés <em>via</em> un script Python dans les fichiers <code>pikachu.xyz</code> et <code>pikachu.edges</code>.</p><p><img src=images/blender_pikachu.png alt="Modèle 3D réalisé dans Blender" class=center><div style=margin-top:1rem></div></p><p><code>pikachu.xyz</code> contains 134 lines and 3 columns, corresponding to the 134 model points and their three \(x, y, z\) coordinates.</p><p><code>pikachu.edges</code> contient 246 lignes et 2 colonnes, correspondant aux 246 arêtes du modèle et aux 2 indices de leurs extrémités (la première arête est définie par son premier point à l&rsquo;indice 2 et par son deuxième point à l&rsquo;indice 0 dans <code>pikachu.xyz</code>).</p><p><img src=images/edges_xyz.png alt="Fichiers de coordonnées et arêtes" class=center><div style=margin-top:1rem></div></p><p>Par &ldquo;transformation&rdquo;, on entend une rotation et une translation de la scène
sur les axes \(x\), \(y\) et \(z\) des points dans \(\mathcal{R_o}\).</p><p>Dans notre cas, on veut augmenter la réalité capturée par la caméra et positionner le modèle de Pikachu sur le cube bleu ciel de l&rsquo;image ci-dessous, en le faisant parfaitement <em>matcher</em> avec le cube virtuel sur lequel il repose.</p><p><img src=images/final_objective.png alt="Objectif à atteindre" class=center><div style=margin-top:1rem></div></p><details><summary><strong>Paramètres intrinsèques. <span style=color:pink>Cliquez pour étendre</span></strong></summary><p>On utilise le modèle de caméra sténopé qui permet de réaliser cette opération en deux transformations successives :\(\mathcal{R_o} \rightarrow \mathcal{R_c}\) puis \(\mathcal{R_c} \rightarrow \mathcal{R_i}\). En plus des repères \(\mathcal{R_o}\) et \(\mathcal{R_i}\), il faut donc aussi considérer le repère caméra \(\mathcal{R_c}\).</p><blockquote><p>La ressource <em><a href=http://www.optique-ingenieur.org/fr/cours/OPI_fr_M04_C01/co/Grain_OPI_fr_M04_C01_2.html>Modélisation et calibrage d&rsquo;une caméra</a></em> décrit en détail le modèle sténopé et peut aider à la compréhension de l&rsquo;exercice.</p></blockquote><p><img src=images/goal.png alt="Changements de repères" class=center><div style=margin-top:1rem></div></p><blockquote><p>Wikipédia définit le <a href=https://en.wikipedia.org/wiki/Pinhole_camera_model>modèle sténopé</a> comme décrivant <em>la relation mathématique entre les coordonnées d&rsquo;un point dans un espace en trois dimensions et sa projection dans le plan image d&rsquo;une caméra sténopé i.e. une caméra dont l&rsquo;ouverture est décrite comme un point et qui n&rsquo;utilise pas de lentille pour focaliser la lumière</em>.</p></blockquote><p>Le passage entre les repères \(\mathcal{R_c}\) anetd \(\mathcal{R_i}\) se fait à l&rsquo;aide des paramètres <strong>intrinsèques</strong> de la caméra. Ces coefficients \((\alpha_u, \alpha_v, u_0, v_0)\) sont ensuite stockés dans une matrice de passage homogène \(K_{i \leftarrow c}\) de sorte que l&rsquo;on peut décrire la relation \(p_i = K_{i \leftarrow c}.P_c\) comme étant :</p><p>$$
\begin{bmatrix}
u\\v\\1
\end{bmatrix}_{\mathcal{R}_i} = s.
\begin{bmatrix}
\alpha_u & 0 & u_0\\<br>0 & \alpha_v & v_0\\<br>0 & 0 & 1
\end{bmatrix} .
\begin{bmatrix}
X\\<br>Y\\<br>Z
\end{bmatrix}_{\mathcal{R}_c}
$$</p><p>avec :</p><ul><li>\(p_i\) (à gauche) le point exprimé en pixels dans le repère 2D image \(\mathcal{R_i}\),</li><li>\(P_c\) (à droite) le point exprimé en centimètres dans le repère 3D caméra \(\mathcal{R_c}\),</li><li>\(s = \frac{1}{Z}\),</li><li>\(\alpha_u = k_x f\), \(\alpha_v = k_y f\) :<ul><li>\(k_x = k_y\) le nombre de pixels par millimètre du capteur dans les directions \(x\) et \(y\) &ndash; l&rsquo;égalité n&rsquo;étant vraie que si les pixels sont carrés,</li><li>\(f\) la distance focale.</li></ul></li><li>\(u_0\) et \(v_0\) les centres de l&rsquo;image en pixels dans \(\mathcal{R}_i\).</li></ul><p>Dans notre cas, l&rsquo;image a été capturée par un Canon EOS 700D dont la taille du capteur est de \(22.3\times14.9 mm\). La taille de l&rsquo;image étant de \(720\times480 px\) et la distance focale de \(18mm\), on en déduit les paramètres \(\alpha_u = 581.1659\), \(\alpha_v = 579.8657\), \(u_0 = 360\) et \(v_0 = 240\) qui sont stockés dans le fichier <code>calibration_parameters.txt</code>.</p></details><details><summary><strong>Paramètres extrinsèques. <span style=color:pink>Cliquez pour étendre</span></strong></summary><p>Pour atteindre notre objectif de départ, c&rsquo;est-à-dire afficher dans l&rsquo;image en pixels notre modèle 3D virtuel, nous devons estimer les coefficients de la transformation \(\mathcal{R_o}\rightarrow\mathcal{R_c}\) permettant d&rsquo;établir la relation \(P_c=M_{c\leftarrow o}.P_o\), avec :</p><ul><li><p>\(M_{c\leftarrow o}=\big[ R_{\alpha\beta\gamma} | T \big]\) la matrice de transformation homogène composée des angles d&rsquo;Euler et de la translation selon les axes \(x\), \(y\) et \(z\) du repère.</p></li><li><p>\(R_{\alpha\beta\gamma}\) la matrice de rotation résultat de l&rsquo;application successive (et donc de la multiplication entre elles) des matrices de rotation \(R_\gamma\), \(R_\beta\) et \(R_\alpha\) :</p></li></ul><p>$$R_\alpha = \begin{bmatrix}1 & 0 & 0\\0 & \cos \alpha & -\sin \alpha\\0 & \sin \alpha & \cos \alpha\end{bmatrix}$$</p><p>$$R_\beta = \begin{bmatrix}\cos \beta & 0 & -\sin \beta\\0 & 1 & 0\\\sin \beta & 0 & \cos \beta\end{bmatrix}$$</p><p>$$R_\gamma = \begin{bmatrix}\cos \gamma & -\sin \gamma & 0\\\sin \gamma & \cos \gamma & 0\\0 & 0 & 1\end{bmatrix}$$</p><p>Avec les bons paramètres extrinsèques \((\alpha, \beta, \gamma, t_x, t_y, t_z)\), le modèle 3D dans son repère \(\mathcal{R_o}\) pourra être transformé jusqu&rsquo;à être exprimé dans \(\mathcal{R_c}\) puis dans \(\mathcal{R_i}\), en respectant la relation suivante pour chaque point \(P_o\) :</p><p>$$ p_i = K_{i \leftarrow c} M_{c\leftarrow o} P_o$$</p><p>$$\begin{bmatrix}
u\\<br>v\\<br>1
\end{bmatrix}_{\mathcal{R}_i} = s.
\begin{bmatrix}
\alpha_u & 0 & u_0\\<br>0 & \alpha_v & v_0\\<br>0 & 0 & 1
\end{bmatrix} \bigodot
\begin{bmatrix}
r_{11} & r_{12} & r_{13} & t_x\\<br>r_{21} & r_{22} & r_{23} & t_y\\<br>r_{31} & r_{32} & r_{33} & t_z\\<br>0 & 0 & 0 & 1
\end{bmatrix} .
\begin{bmatrix}
X\\<br>Y\\<br>Z\\<br>1
\end{bmatrix}_{\mathcal{R}_o}
$$</p><div class="alert alert-warning"><strong>L&rsquo;opérateur \(\bigodot\) indique la multiplication des termes après avoir enlevé la coordonnée homogène de \(M_{c\leftarrow o} P_o\). Il est simplement là pour que les tailles de matrice soient correctes.</strong></div></details></br><blockquote><p>Les paramètres intrinsèques sont connus ; pour trouver les paramètres extrinsèques nous utiliserons une méthode de localisation (<em>i.e.</em> d&rsquo;estimation des paramètres) dite <em>par recalages successifs</em>, appelée <strong>Perspective-n-Lignes</strong>.</p></blockquote><h3 id=estimation-des-paramètres-extrinsèques>Estimation des paramètres extrinsèques</h3><p>On démarre d&rsquo;une estimation initiale grossière des paramètres \((\alpha, \beta, \gamma, t_x, t_y, t_z)\). Cette estimation initiale est plus ou moins juste en fonction de la connaissance que l&rsquo;on a <em>a priori</em> de la scène, de l&rsquo;objet, de la position de la caméra.</p><p>Dans notre cas, les paramètres initiaux ont pour valeurs \(alpha = -2.1\), \(beta = 0.7\), \(gamma = 2.7\), \(t_x = 3.1\), \(t_y = 1.3\) et \(t_z = 18\), c&rsquo;est-à-dire que l&rsquo;on sait avant même de commencer que le modèle 3D devra subir une rotation d&rsquo;angles \((-2.1, 0.7, 2.7)\) autour de ses trois axes, et qu&rsquo;il devra se décaler d&rsquo;environ \(3cm\) en \(x\), \(1.5cm\) en \(y\) and \(18cm\) en \(z\).</p><blockquote><p>Cette connaissance <em>a priori</em> de la scène vient du fait que l&rsquo;on est capable, en tant qu&rsquo;humain, d&rsquo;évaluer la distance de l&rsquo;objet réel par rapport au capteur seulement en regardant l&rsquo;image.</p></blockquote><h3 id=utilisation-du-programme>Utilisation du programme</h3><p>Au lancement du script <code>localisation.py</code>, deux figures s&rsquo;ouvrent : l&rsquo;une représente une scène réelle capturée par la caméra, l&rsquo;autre représente le modèle virtuel à transformer et dont l&rsquo;origine du repère est matérialisée par un point rouge. L&rsquo;objectif étant de venir calquer la boite sur laquelle repose le Pikachu par-dessus le cube bleu ciel posé sur la table, il faut dans un premier temps sélectionner cinq arêtes appartenant à la boite réelle (par <em>click</em> souris sur les extrémités des arêtes), puis sélectionner dans le même ordre les arêtes correspondantes sur le modèle 3D (par <em>click</em> souris au milieu des arêtes). Le nombre de segments à sélectionner (par défaut 5), est fixé dès le départ dans la variable <code>nb_segments</code>.</p><p><img src=images/edge_selection.png alt="Sélection des arêtes dans l'image et dans le modèle 3D" class=center><div style=margin-top:1rem></div></p><p>De cette manière, on pourra calculer l&rsquo;erreur commise sur l&rsquo;estimation des paramètres extrinsèques en comparant la distance entre les arêtes sélectionnées dans l&rsquo;image et celles du modèle transformé. Ce critère d&rsquo;erreur est décrit à l'<a href=#anchor-step-2>étape 2</a>.</p><h2 id=anchor-step-1><em><strong>Etape 1</strong></em> : afficher le modèle dans \(\mathcal{R_i}\)</h2><p>Dans le programme principal, les points du modèle sont stockés dans <code>model3d_Ro</code>, une matrice de taille \([246\times6]\) correspondant aux 246 arêtes du modèle, chacune définie par les 6 coordonnées de ses deux points \(P_1(x_1, y_1, z_1)\) et \(P_2(x_2, y_2, z_2)\). La matrice de transformation \(M_{c\leftarrow o}\) est stockée dans <code>extrinsic_matrix</code> et les paramètres intrinsèques de la caméra sont stockés dans <code>intrinsic_matrix</code>.</p><p>Pour visualiser le modèle 3D dans l&rsquo;image 2D et se faire une idée de la justesse de notre estimation, il faut coder la fonction <code>tranform_and_draw_model</code> qui permet d&rsquo;appliquer la transformation \(K_{i \leftarrow c} M_{c\leftarrow o}\) à chaque point \(P_o\) d&rsquo;un ensemble d&rsquo;arêtes' <code>edges_Ro</code>, avec une matrice <code>intrinsic</code>, et une matrice <code>extrinsic</code> pour finalement afficher le résultat dans une figure <code>fig_axis</code> :</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>transform_and_draw_model</span>(edges_Ro, intrinsic, extrinsic, fig_axis):
    <span style=color:#75715e># ********************************************************************* #</span>
    <span style=color:#75715e># A COMPLETER.                                                          #</span>
    <span style=color:#75715e># UTILISER LES FONCTIONS :                                              #</span>
    <span style=color:#75715e>#   - perspective_projection                                            #  </span>
    <span style=color:#75715e>#   - transform_point_with_matrix                                       #</span>
    <span style=color:#75715e># Input:                                                                #</span>
    <span style=color:#75715e>#   edges_Ro : ndarray[Nx6]                                             #</span>
    <span style=color:#75715e>#             N = nombre d&#39;aretes dans le modele                        #</span>
    <span style=color:#75715e>#             6 = (X1, Y1, Z1, X2, Y2, Z2) les coordonnees des points   #</span>
    <span style=color:#75715e>#                 P1 et P2 de chaque arete                              #</span>
    <span style=color:#75715e>#   intrinsic : ndarray[3x3] - parametres intrinseques de la camera     #</span>
    <span style=color:#75715e>#   extrinsic : ndarray[4x4] - parametres extrinseques de la camera     #</span>
    <span style=color:#75715e>#   fig_axis : figure utilisee pour l&#39;affichage                         #</span>
    <span style=color:#75715e># Output:                                                               #</span>
    <span style=color:#75715e>#   Pas de retour de fonction, mais calcul et affichage des points      #</span>
    <span style=color:#75715e>#   transformes (u1, v1) et (u2, v2)                                    #</span>
    <span style=color:#75715e># ********************************************************************* #</span>

    <span style=color:#75715e># Part to replace #</span>
    u_1 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((edges_Ro<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>],<span style=color:#ae81ff>1</span>))
    u_2 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((edges_Ro<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>],<span style=color:#ae81ff>1</span>))
    v_1 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((edges_Ro<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>],<span style=color:#ae81ff>1</span>))
    v_2 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((edges_Ro<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>],<span style=color:#ae81ff>1</span>))
    <span style=color:#75715e>############### </span>
    
    <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> range(edges_Ro<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]):
        fig_axis<span style=color:#f92672>.</span>plot([u_1[p], u_2[p]], [v_1[p], v_2[p]], <span style=color:#e6db74>&#39;k&#39;</span>)
</code></pre></div><p>L&rsquo;objectif est de stocker dans les points <code>[u_1, v_1]</code> et <code>[u_2, v_2]</code> les coordonnées \((u, v)\) des points \(P_1\) et \(P_2\) des arêtes après transformation.</p><p>On peut découper cette fonction en deux sous-étapes :</p><ul><li><p>la transformation \(\mathcal{R_o} \rightarrow \mathcal{R_c}\) des points \(P_o\) à l&rsquo;aide de la fonction <code>transform_point_with_matrix</code> fournie dans la librairie <code>matTools</code> :</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>P_c <span style=color:#f92672>=</span> matTools<span style=color:#f92672>.</span>transform_point_with_matrix(extrinsic, P_o)
</code></pre></div></li><li><p>la projection \(\mathcal{R_c} \rightarrow \mathcal{R_i}\) des points nouvellement obtenus \(P_c\) à l&rsquo;aide de la fonction <code>perspective_projection</code> qu&rsquo;il faut compléter :</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>perspective_projection</span>(intrinsic, P_c):
    <span style=color:#75715e># ***************************************************** #</span>
    <span style=color:#75715e># A COMPLETER.                                          #</span>
    <span style=color:#75715e># Fonction utile disponible :                           #</span>
    <span style=color:#75715e>#   np.dot                                              #</span>
    <span style=color:#75715e># Input:                                                #</span>
    <span style=color:#75715e>#   intrinsic : ndarray[3x3] - parametres intrinseques  #</span>
    <span style=color:#75715e>#   P_c : ndarray[Nx3],                                 #</span>
    <span style=color:#75715e>#         N = nombre de points à transformer            #</span>
    <span style=color:#75715e>#         3 = (X, Y, Z) les coordonnees des points      #</span>
    <span style=color:#75715e># Output:                                               #</span>
    <span style=color:#75715e>#   u, v : deux ndarray[N] contenant les                #</span>
    <span style=color:#75715e>#          coordonnees Ri des points P_c transformes    #</span>
    <span style=color:#75715e># ***************************************************** #</span>
      
    u, v <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span> <span style=color:#75715e># Part to replace</span>
      
    <span style=color:#66d9ef>return</span> u, v
</code></pre></div></li></ul><p>Une fois <code>perspective_projection</code> et <code>transform_and_draw_model</code> complétées, le lancement du programme global projette le modèle dans l&rsquo;image, avec les paramètres extrinsèques définis au départ.</p><p><img src=images/first_rough_estimate.png alt="Première projection du modèle dans l'image" class=center><div style=margin-top:1rem></div></p><blockquote><p>La transformation appliquée à ces points n&rsquo;est visiblement pas très bonne, le modèle ne <em>matche</em> pas la boite comme on le souhaiterait. Pour pouvoir différencier une &ldquo;mauvaise&rdquo; estimation des paramètres extrinsèques d&rsquo;une &ldquo;bonne&rdquo;, et ainsi pouvoir proposer de manière automatique une nouvelle estimation plus proche de notre objectif, il faut déterminer un critère d&rsquo;erreur caractérisant la distance à laquelle on se trouve de cet objectif optimal.</p></blockquote><h2 id=anchor-step-2><em><strong>Etape 2</strong></em> : déterminer un critère d&rsquo;erreur</h2><p>Le critère d&rsquo;erreur sert à évaluer la justesse de notre estimation. Plus l&rsquo;erreur est grande, moins nos paramètres extrinsèques sont bons. Après avoir déterminé ce critère d&rsquo;erreur, on pourra l&rsquo;intégrer dans une boucle d&rsquo;optimisation visant à le minimiser, et donc à avoir des paramètres extrinsèques les meilleurs possibles pour notre objectif d&rsquo;appariement 2D/3D.</p><p>A titre d&rsquo;exemple, la figure ci-dessous illustre cette boucle d&rsquo;optimisation pour la projection de la boite virtuelle sur le cube réel. A l&rsquo;itération \(0\), les paramètres sont grossiers, l&rsquo;erreur est grande. En modifiant les paramètres on fera diminuer l&rsquo;erreur jusqu&rsquo;à atteindre, dans l&rsquo;idéal, une erreur nulle et une transformation optimale pour une projection parfaite du modèle 3D dans l&rsquo;image 2D.</p><p><img src=images/extrinsic_optim.gif alt="Optimisation des paramètres extrinsèques" class=center><div style=margin-top:1rem></div></p><p>Dans le cadre de l&rsquo;appariement 2D/3D de segments, le critère d&rsquo;erreur à minimiser correspond au produit scalaire de la normale au plan d&rsquo;interprétation relatif à l&rsquo;appariement. En d&rsquo;autres termes, l&rsquo;objectif est de transformer les points du modèle de sorte que les segments sélectionnés dans l&rsquo;image et ceux sélectionnés dans le modèle appartiennent au même plan exprimé dans le repère caméra \(\mathcal{R_c}\).</p><p><img src=images/interpretation_plan.png alt="Plan d'interprétation relatif à l'appariement de droites" class=center><div style=margin-top:1rem></div></p><p>Comme le montre la figure ci-dessus, on peut définir le <em>plan d&rsquo;interprétation</em> comme étant formé par les segments \(\mathcal{l_{i \rightarrow c}^{j,1}}\) et \(\mathcal{l_{i \rightarrow c}^{j,2}}\). Dans cette notation, \(j\) correspond au nombre d&rsquo;arêtes sélectionnées au lancement du programme (5 par défaut). Pour chaque arête sélectionnée \(j\) et exprimée dans le repère <em>image</em> \(\mathcal{R_i}\), on a donc deux segments \(l^1\) et \(l^2\). Le segment \(l^1\) est composé des deux extrémités \(P_{i \rightarrow c}^0\) et \(P_{i \rightarrow c}^1\) ; le segment \(l^2\) est composé des deux extrémités \(P_{i \rightarrow c}^1\) et \(P_{i \rightarrow c}^2\). Chacun des \(P_{i \rightarrow c}\) est un point du repère <em>image</em> \(\mathcal{R_i}\) transformé dans le repère <em>caméra</em> \(\mathcal{R_c}\). Ils sont connus : ce sont ceux qui ont été sélectionnés par <em>click</em> souris.</p><p>Une fois ces segments calculés, on peut calculer la normale au plan d&rsquo;interprétation \(N_c^j\). Pour rappel :</p><p>$$N = \frac{l^1 \wedge l^2}{||l^1 \wedge l^2||}$$</p><p>Dans la fonction de sélection des segments <code>utils.select_segments()</code>, au fil des sélections d&rsquo;arêtes, les normales sont calculées et stockées dans la matrice <code>normal_vectors</code> grâce à la fonction <code>calculate_normal_vector</code> qu&rsquo;il faut compléter dans le fichier <code>localisation.py</code> :</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>calculate_normal_vector</span>(p1_Ri, p2_Ri, intrinsic):
    <span style=color:#75715e># ********************************************************* #</span>
    <span style=color:#75715e># A COMPLETER.                                              #</span>
    <span style=color:#75715e># Fonctions utiles disponibles :                            #</span>
    <span style=color:#75715e>#   np.dot, np.cross, np.linalg.norm, np.linalg.inv         #</span>
    <span style=color:#75715e># Input:                                                    #</span>
    <span style=color:#75715e>#   p1_Ri : list[3]                                         #</span>
    <span style=color:#75715e>#           3 = (u, v, 1) du premier point selectionne      #</span>
    <span style=color:#75715e>#   p2_Ri : list[3]                                         #</span>
    <span style=color:#75715e>#           3 = (u, v, 1) du deuxieme point selectionne     #</span>
    <span style=color:#75715e>#   intrinsic : ndarray[3x3] des intrinseques               #</span>
    <span style=color:#75715e># Output:                                                   #</span>
    <span style=color:#75715e>#   normal_vector : ndarray[3] contenant la normale aux     #</span>
    <span style=color:#75715e>#                   segments L1_c et L2_c deduits des       #</span>
    <span style=color:#75715e>#                   points image selectionnes               #</span>
    <span style=color:#75715e># ********************************************************* #</span>

    normal_vector <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((len(p1_Ri),)) <span style=color:#75715e># Part to replace</span>

    <span style=color:#66d9ef>return</span> normal_vector
</code></pre></div><p>Ensuite, pour chaque segment \(j \in [1, &mldr;, 5]\), la distance entre le plan lié aux segments image et les points du modèle 3D peut être calculée grâce au produit scalaire des \(N_c^j\) et des \(P_{o\rightarrow c}^j\). Si le produit scalaire est nul, les deux vecteurs sont orthogonaux et le point \(P_{o\rightarrow c}^j\) appartient bien au même plan que \(P_{i \rightarrow c}^j\). Plus le produit scalaire est grand, plus les paramètres extrinsèques s&rsquo;éloignent de la bonne transformation.</p><p>Pour résumer, le critère d&rsquo;optimisation des paramètres est \(\sum_{j=1}^{2n} F^j(X)^2\) (le carré enlève les valeurs négatives), avec \(F^j(X) = N^{j ; \text{mod} ; 2}.P_{o\rightarrow c}^{j ; \text{mod} ; 2, 1|2}\), selon que l&rsquo;on se trouve sur le point \(P^{1}\) ou \(P^{2}\).</p><blockquote><p>Dans la somme qui parcourt les points de \(j\) à \(2n\), \(j ; \text{mod} ; 2\) est l&rsquo;indice du segment pour le point courant. Autrement dit, on cumule les \((N^i.P^{i, 1})^2\) et \((N^i.P^{i, 2})^2\) pour tous les segments \(i\).</p></blockquote><div class="alert alert-warning"><strong>Ici, \(X\) désigne l&rsquo;ensemble des paramètres \((\alpha, \beta, \gamma, t_x, t_y, t_z)\) et non une coordonnée.</strong></div><p>On rappelle que chaque \(P_{o\rightarrow c} = \big[ R_{\alpha\beta\gamma} | T \big]. P_o\) ; la valeur de l&rsquo;erreur dépend donc bien de la valeur des paramètres extrinsèques. A chaque passage dans la boucle d&rsquo;optimisation, changer les poids de ces paramètres aura une influence sur le critère \(F(X)\).</p><p>La fonction <code>calculate_error</code> calcule le critère d&rsquo;erreur. Elle prend en entrée le nombre <code>nb_segments</code> d&rsquo;arêtes sélectionnées, les <code>normal_vectors</code>, et les <code>segments_Rc</code> sélectionnés puis transformés par la matrice des paramètres extrinsèques et exprimés dans \(\mathcal{R_c}\).</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>calculate_error</span>(nb_segments, normal_vectors, segments_Rc):
    <span style=color:#75715e># ***************************************************************** #</span>
    <span style=color:#75715e># A COMPLETER.                                                      #</span>
    <span style=color:#75715e># Input:                                                            #</span>
    <span style=color:#75715e>#   nb_segments : par defaut 5 = nombre de segments selectionnes    #</span>
    <span style=color:#75715e>#   normal_vectors : ndarray[Nx3] - normales aux plans              #</span>
    <span style=color:#75715e>#                    d&#39;interpretation des segments selectionnes     #</span>
    <span style=color:#75715e>#                    N = nombre de segments                         #</span>
    <span style=color:#75715e>#                    3 = coordonnees (X,Y,Z) des normales dans Rc   #</span>
    <span style=color:#75715e>#   segments_Rc : ndarray[Nx6] = segments selectionnes dans Ro      #</span>
    <span style=color:#75715e>#                 et transformes dans Rc                            #</span>
    <span style=color:#75715e>#                 N = nombre de segments                            #</span>
    <span style=color:#75715e>#                 6 = (X1, Y1, Z1, X2, Y2, Z2) des points P1 et     #</span>
    <span style=color:#75715e>#                 P2 des aretes transformees dans Rc                #</span>
    <span style=color:#75715e># Output:                                                           #</span>
    <span style=color:#75715e>#   err : float64 - erreur cumulee des distances observe/attendu    #</span>
    <span style=color:#75715e># </span>
    <span style=color:#75715e># ***************************************************************** #</span>
    err <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> range(nb_segments):
        <span style=color:#75715e># Part to replace with the error calculation</span>
        err <span style=color:#f92672>=</span> err <span style=color:#f92672>+</span> <span style=color:#ae81ff>0</span>
    
    err <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sqrt(err <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> nb_segments)
    <span style=color:#66d9ef>return</span> err
</code></pre></div><blockquote><p>D&rsquo;un point de vue mathématique, la somme est écrite pour \(j\) allant de \(1\) à \(2n\), <em>i.e.</em> le nombre de points. D&rsquo;un point de vue implémentation et étant donnée la construction de nos variables, il est plus simple d&rsquo;exprimer le critère au travers d&rsquo;une somme parcourant les arêtes : \(\sum_{j=1}^{n} F^j(X)\) with \(F^{j}(X) = F^{j, 1}(X)^2 + F^{j, 2}(X)^2\).</p><p>Ainsi, \(F^{j, 1}(X) = N^j.P_{o\rightarrow c}^{j, 1}\) et \(F^{j, 2}(X) = N^j.P_{o\rightarrow c}^{j, 2}\).</p></blockquote><h2 id=anchor-step-3><em><strong>Etape 3</strong></em> : Estimation des paramètres par la méthode des moindres carrés ordinaires</h2><p>A chaque itération \(k\), on cherche un jeu de paramètres \(X_{k}(\alpha, \beta, \gamma, t_x, t_y, t_z)\) tel que le critère \(F(X)\) soit égal au critère pour le jeu de paramètres précédent \(X_0\) (avant mise à jour) incrémenté d&rsquo;un delta pondéré par la jacobienne de la fonction.</p><p>On cherche donc à résoudre un système de la forme :</p><p>$$F(X) \approx F(X_0) + J \Delta X$$</p><blockquote><p>La jacobienne \(J\) contient sur ses lignes les dérivées partielles de la fonction \(F\) pour chaque point sélectionné et selon chacun des paramètres de \(X\). Elle traduit la tendance du critère (montant/descendant) et la vitesse à laquelle il augmente ou diminue en fonction de la valeur de chacun de ses paramètres.</p></blockquote><p>Notre objectif étant d&rsquo;atteindre un critère \(F(X) = 0\), on traduit le problème à résoudre par :</p><p>$$
\begin{align}
0 &= F(X_0) + J \Delta X \\\<br>\Leftrightarrow \qquad -F(X_0) &= J\Delta X
\end{align}
$$</p><p>L&rsquo;intérêt de travailler par incréments successifs est d&rsquo;avoir des valeurs d&rsquo;incrément si petites par rapport à la dernière itération qu&rsquo;on peut approximer la variation de ces paramètres comme étant égale à 0. Pour rappel, le critère d&rsquo;erreur s&rsquo;exprime de la manière suivante pour chaque segment \(j\) :</p><p>$$
\begin{align}
F^{j, 1}(X) &= N^j.P_{o\rightarrow c}^{j, 1} \text{ avec } P_{o\rightarrow c}^{j, 1} = \big[ R_{\alpha\beta\gamma
} | T \big] . P_o^{j, 1}\\\<br>F^{j, 2}(X) &= N^{j}.P_{o\rightarrow c}^{j, 2} \text{ avec } P_{o\rightarrow c}^{j, 2} = \big[ R_{\alpha\beta\gamma
} | T \big] . P_o^{j, 2}
\end{align}$$</p><p>Du fait de toujours avoir des\(\Delta X \approx 0\), le calcul de la matrice jacobienne se retrouve considérablement simplifié, puisque les dérivées partielles \((\frac{\partial F^j}{\partial \alpha}, \frac{\partial F^j}{\partial \beta}, \frac{\partial F^j}{\partial \gamma}, \frac{\partial F^j}{\partial t_x}, \frac{\partial F^j}{\partial t_y}, \frac{\partial F^j}{\partial t_z})\) sont les mêmes à chaque itération.</p><p>Le détail de la dérivation est donné pour le premier paramètre \(\alpha\), les suivants sont à démontrer :</p><p>$$\begin{align}
\frac{\partial F^j}{\partial \alpha} &= N^j . [R_\gamma . R_\beta . \frac{\partial R_\alpha}{\partial \alpha} | T] . P_o^j\\\<br>\end{align}$$</p><div class="alert alert-info"><strong><p>\(R_\gamma\) et \(R_\beta\) disparaissent de la dérivation car pour \(\gamma \approx 0\) et \(\beta \approx 0\), on a :</p><p>$$
R_{\gamma \approx 0} = \begin{bmatrix}
\cos 0 & -\sin 0 & 0\\\
\sin 0 & \cos 0 & 0\\\
0 & 0 & 1 \end{bmatrix} = \begin{bmatrix}
1 & 0 & 0\\\
0 & 1 & 0\\\
0 & 0 & 1 \end{bmatrix} = I_3
$$</p><p>$$
R_{\beta \approx 0} = \begin{bmatrix}
\cos 0 & 0 & -\sin 0\\\<br>0 & 1 & 0\\\<br>\sin 0 & 0 & \cos 0 \end{bmatrix} = \begin{bmatrix}
1 & 0 & 0\\\
0 & 1 & 0\\\
0 & 0 & 1 \end{bmatrix} = I_3
$$</p><p>\(T\) disparaît puisque \(t_x\), \(t_y\), \(t_z \approx 0\).</p><p><em>Rappel de règles de dérivation : \((\text{constant } a)' \rightarrow 0 \text{, } (\sin)' \rightarrow \cos \text{, } (\cos)' \rightarrow -\sin\).</em></p></strong></div><p>$$\begin{align}
\frac{\partial F^j}{\partial \alpha} &= N^j . [I_3 . I_3 . \frac{\partial R_\alpha}{\partial \alpha} | 0] .
P_o^j\\\<br>&= N^j . \frac{\partial \begin{bmatrix}1 & 0 & 0\\\ 0 & \cos (\alpha \approx 0) & -\sin (\alpha \approx 0)\\\ 0 & \sin (\alpha \approx 0) & \cos (\alpha \approx 0) \end{bmatrix}}{\partial \alpha} . \begin{bmatrix}X^j\\\ Y^j\\\ Z^j\end{bmatrix}_o\\\<br>&= N^j . \begin{bmatrix}0 & 0 & 0\\\ 0 & -\sin (\alpha \approx 0) & -\cos (\alpha \approx 0)\\\ 0 & \cos (\alpha \approx 0) & -\sin (\alpha \approx 0) \end{bmatrix} . \begin{bmatrix}X^j\\\ Y^j\\\ Z^j\end{bmatrix}_o\\\<br>&= N^j . \begin{bmatrix}0 & 0 & 0\\\ 0 & 0 & -1\\\ 0 & 1 & 0 \end{bmatrix} . \begin{bmatrix}X^j\\\ Y^j\\\ Z^j\end{bmatrix}_o\\\<br>&= N^j . \begin{bmatrix}0\\\ -Z^j\\\ Y^j\end{bmatrix}_o\\\<br>\end{align}$$</p><p>Le raisonnement est le même pour \(\frac{\partial F^j}{\partial \beta}, \frac{\partial F^j}{\partial \gamma}, \frac{\partial F^j}{\partial t_x}, \frac{\partial F^j}{\partial t_y}, \frac{\partial F^j}{\partial t_z}\) et on obtient :</p><p>$$
\frac{\partial F^j}{\partial \beta} = N^j . \begin{bmatrix}Z^j\\\ 0\\\ -X^j\end{bmatrix}_o \text{, }
\frac{\partial F^j}{\partial \gamma} = N^j . \begin{bmatrix}-Y^j\\\ X^j\\\ 0\end{bmatrix}_o
$$
$$
\frac{\partial F^j}{\partial t_x} = N_x^j \text{, }
\frac{\partial F^j}{\partial t_y} = N_y^j \text{, }
\frac{\partial F^j}{\partial t_z} = N_z^j
$$</p><p>Chacune de ces dérivées partielles est à implémenter dans la fonction <code>partial_derivatives</code> :</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>partial_derivatives</span>(normal_vector, P_c):
    <span style=color:#75715e># ********************************************************************* #</span>
    <span style=color:#75715e># A COMPLETER.                                                          #</span>
    <span style=color:#75715e># Input:                                                                #</span>
    <span style=color:#75715e>#   normal_vector : ndarray[3] contenant la normale pour le segment     #</span>
    <span style=color:#75715e>#                   auquel appartient P_c                               #</span>
    <span style=color:#75715e>#   P_c : ndarray[3] le point de l&#39;objet transformé dans Rc             #</span>
    <span style=color:#75715e># Output:                                                               #</span>
    <span style=color:#75715e>#   partial_derivative : ndarray[6] derivee partielle du critere        #</span>
    <span style=color:#75715e>#               d&#39;erreur pour chacun des parametres extrinseques        #</span>
    <span style=color:#75715e>#   crit_X0 : float64 - valeur du critere pour les parametres           #</span>
    <span style=color:#75715e>#               courants, qui servira de valeur initiale avant          #</span>
    <span style=color:#75715e>#               la mise a jour et le recalcul de l&#39;erreur               #</span>
    <span style=color:#75715e># ********************************************************************* #</span>
    X, Y, Z <span style=color:#f92672>=</span> P_c[<span style=color:#ae81ff>0</span>], P_c[<span style=color:#ae81ff>1</span>], P_c[<span style=color:#ae81ff>2</span>]
    partial_derivative <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((<span style=color:#ae81ff>6</span>))
    
    <span style=color:#75715e># Variable a remplir</span>
    partial_derivative[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    partial_derivative[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    partial_derivative[<span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    partial_derivative[<span style=color:#ae81ff>3</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    partial_derivative[<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    partial_derivative[<span style=color:#ae81ff>5</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>

    <span style=color:#75715e># ********************************************************************</span>
    crit_X0 <span style=color:#f92672>=</span> normal_vector[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>*</span> X <span style=color:#f92672>+</span> normal_vector[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>*</span> Y <span style=color:#f92672>+</span> normal_vector[<span style=color:#ae81ff>2</span>] <span style=color:#f92672>*</span> Z
    <span style=color:#66d9ef>return</span> partial_derivative, crit_X0
</code></pre></div><p>On peut ainsi formaliser le problème comme étant :</p><p>$$
F = J \Delta X \text{ avec } F = \begin{bmatrix}-F^1(X_0) \\\ \vdots \\\ -F^{2n}(X_0)\end{bmatrix}_{2n\times 1}
$$
$$
\text{ et } J = \begin{bmatrix}\frac{\partial F^1}{\partial \alpha} & \frac{\partial F^1}{\partial \beta} & \frac{\partial F^1}{\partial \gamma} & \frac{\partial F^1}{\partial t_x} & \frac{\partial F^1}{\partial t_y} & \frac{\partial F^1}{\partial t_z}\\\ \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\\ \frac{\partial F^{2n}}{\partial \alpha} & \frac{\partial F^{2n}}{\partial \beta} & \frac{\partial F^{2n}}{\partial \gamma} & \frac{\partial F^{2n}}{\partial t_x} & \frac{\partial F^{2n}}{\partial t_y} & \frac{\partial F^{2n}}{\partial t_z}\end{bmatrix}_{2n\times 6}
$$
$$
\text{ et } \Delta X = \begin{bmatrix}\Delta \alpha \\\ \vdots \\\ \Delta t_z\end{bmatrix}_{6 \times 1}
$$</p><blockquote><p>\(2n\) est le nombre de points sélectionnés, \(n\) est le nombre d&rsquo;arêtes (une arête = deux extrémités).</p></blockquote><p>\(F\) est connue, \(J\) est connue, il ne reste plus qu&rsquo;à estimer \(\Delta X\) de sorte que l&rsquo;égalité \(F = J \Delta X\) soit &ldquo;la plus vraie possible&rdquo;. Pour cela, on souhaite minimiser la distance entre les deux côtés de l&rsquo;égalité :</p><p>$$
\begin{align}
\min_{\Delta X} ||F - J\Delta X||^2 & \\\<br>\Leftrightarrow \qquad \frac{\partial ||F - J\Delta X||^2}{\partial \Delta X} &= 0
\end{align}
$$</p><blockquote><p>En effet, si la dérivée de la fonction à minimiser est 0, alors la courbe de la fonction a bien atteint un minimum.</p></blockquote><div class="alert alert-info"><strong><p><em>Rappel des opérations sur les matrices :</em></p><p>\((A+B)^T = A^T + B^T\)</p><p>\((AB)^T = B^T A^T\)</p><p>\(A\times B \neq B\times A\)</p><p>\(A^2 = A^T A\)</p></strong></div><p>En développant \((F - J \Delta X)^2\), on arrive à :</p><p>$$
\begin{align}
(F - J \Delta X)^2 & = (F - J \Delta X)^T(F - J \Delta X)\\\<br>&= (F^T - \Delta X^T J^T)(F - J \Delta X)\\\<br>&= F^TF - F^TJ\Delta X - \Delta X^T J^T F + \Delta X^T J^T J \Delta X
\end{align}
$$</p><p>On se sert des propriétés matricielles pour montrer que \(F^TJ\Delta X = ((J\Delta X)^T F)^T = (\Delta X^T J^T F)^T\). Considérons les tailles de matrices d&rsquo;un côté et de l&rsquo;autre de l&rsquo;équation :
$$
\begin{align}
F^TJ\Delta X &\rightarrow [1\times2n][2n\times 6][6\times 1] \rightarrow [1\times 1]\\\<br>(\Delta X^T J^T F)^T &\rightarrow [1\times6][6\times 2n][2n\times 1] \rightarrow [1\times 1]
\end{align}
$$</p><p>Etant donné que chacun de ces termes représente une matrice \([1\times 1]\), on peut écrire \((\Delta X^T J^T F)^T = \Delta X^T J^T F\), et par conséquent \(F^TJ\Delta X = \Delta X^T J^T F\).</p><p>On en déduit :
$$
\begin{align}
(F - J \Delta X)^2 & = F^TF - 2\Delta X^T J^T F + \Delta X^T J^T J \Delta X\\\<br>\end{align}
$$</p><div class="alert alert-info"><strong><p><em>Quelques règles de dérivation :</em></p><p>\(\frac{\partial AX}{\partial X} = A^T\), \(\frac{\partial X^TA^T}{\partial X} = A^T\), \(\frac{\partial X^TAX}{\partial X} = 2AX\).</p></strong></div><p>$$
\begin{align}
\frac{\partial (F - J \Delta X)^2}{\partial \Delta X} & = -2J^T F + 2 J^T J \Delta X\\\<br>&= -J^T F + J^T J \Delta X\\\<br>\Leftrightarrow \qquad J^T F &= J^T J \Delta X \\\<br>(J^TJ)^{-1} J^T F &= \Delta X \\\<br>\end{align}
$$</p><p><strong>En résumé :</strong></p><ul><li>minimiser la distance entre \(F\) et \(J\Delta X\) revient à dire que \(\frac{\partial (F - J \Delta X)^2}{\partial \Delta X} = 0\)</li><li>la solution est \(\Delta X = (J^TJ)^{-1} J^T F\).</li></ul><blockquote><p>La matrice \(J^+ = (J^TJ)^{-1} J^T\) s&rsquo;appelle la <em>pseudo-inverse</em> de \(J\).</p></blockquote><p>Dans le code Python, on peut ainsi implémenter la mise à jour des paramètres dans la boucle d&rsquo;optimisation. \(\Delta X\) correspond à la variable nommée <code>delta_solution</code>. On peut ensuite passer <code>delta_solution</code> à la fonction <code>matTools.construct_matrix_from_vec</code> qui renvoie une matrice des incréments de \(X\) de la même forme que <code>extrinsic</code> (la matrice des paramètres extrinsèques).</p><p>On incrémente chacun des éléments de <code>extrinsic</code> en la multipliant par <code>delta_extrinsic</code>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># ********************************************************************* #</span>
<span style=color:#75715e># A COMPLETER.                                                          #</span>
<span style=color:#75715e># delta_solution = ...                                                  #</span>
<span style=color:#75715e># delta_extrinsic = matTools.construct_matrix_from_vec(delta_solution)  #</span>
<span style=color:#75715e># extrinsic = ...                                                       #</span>
<span style=color:#75715e># ********************************************************************* #</span>
</code></pre></div><p>Une fois la boucle d&rsquo;optimisation opérationnelle, on peut visualiser la transformation du modèle sans la boite virtuelle en enlevant les 12 premiers points de <code>model3D_Ro</code> :</p><p><img src=images/final_objective_without_box.png alt="Transformation du modèle après estimation de la pose caméra" class=center><div style=margin-top:1rem></div></p><h2 id=anchor-step-4><em><strong>Etape 4</strong></em> : projection de la pose estimée sur l&rsquo;image prise d&rsquo;un point de vue différent</h2><p>Une deuxième photo a été capturée d&rsquo;un point de vue différent, et la matrice de passage entre le premier et le deuxième point de vue est stockée et chargée en début de programme depuis le fichier <code>.txt</code> correspondant. Elle permet de re-projeter le modèle dans l&rsquo;image issue de la deuxième caméra et d&rsquo;en afficher le résultat :</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>fig5 <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(<span style=color:#ae81ff>5</span>)
ax5 <span style=color:#f92672>=</span> fig5<span style=color:#f92672>.</span>add_subplot(<span style=color:#ae81ff>111</span>)
ax5<span style=color:#f92672>.</span>set_xlim(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>720</span>)
ax5<span style=color:#f92672>.</span>set_ylim(<span style=color:#ae81ff>480</span>)
plt<span style=color:#f92672>.</span>imshow(image_2)

<span style=color:#75715e># A completer avec la matrice de passage du repere Ro vers Rc2, avec les matrices </span>
<span style=color:#75715e># Ro -&gt; Rc et Rc -&gt; Rc2</span>
Ro_to_Rc2 <span style=color:#f92672>=</span> <span style=color:#f92672>...</span>

transform_and_draw_model(model3D_Ro[<span style=color:#ae81ff>12</span>:], intrinsic_matrix, Ro_to_Rc2, ax5)
plt<span style=color:#f92672>.</span>show(block <span style=color:#f92672>=</span> False)
</code></pre></div><p><img src=images/left_to_right.png alt="Projection dans la deuxième image" class=center><div style=margin-top:1rem></div></p><h2 id=bonus>Bonus pour la fin</h2><p>Grâce à la matrice des paramètres extrinsèques estimée, et tant que l&rsquo;origine du repère objet ne change pas, on peut ajouter des éléments à la scène 3D et les projeter dans l&rsquo;image de manière identique. <code>model3D_Ro_final</code> contient les points d&rsquo;une scène contenant Pikachu et un dinosaure.</p><p><img src=images/pika_dino_blender.png alt="Ajout d'élements à la scène 3D" class=center><div style=margin-top:1rem></div></p><p>On décommente les dernières lignes d&rsquo;affichage pour obtenir le résultat final :</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>fig6 <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(<span style=color:#ae81ff>6</span>)
ax6, lines <span style=color:#f92672>=</span> utils<span style=color:#f92672>.</span>plot_3d_model(model3D_Ro_final, fig6)

fig7 <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(<span style=color:#ae81ff>7</span>)
ax7 <span style=color:#f92672>=</span> fig7<span style=color:#f92672>.</span>add_subplot(<span style=color:#ae81ff>111</span>)
ax7<span style=color:#f92672>.</span>set_xlim(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>720</span>)
plt<span style=color:#f92672>.</span>imshow(image)
transform_and_draw_model(model3D_Ro_final[<span style=color:#ae81ff>12</span>:], intrinsic_matrix, extrinsic_matrix, ax7)
plt<span style=color:#f92672>.</span>show(block<span style=color:#f92672>=</span>True)
</code></pre></div><p><img src=images/pika_dino.png alt="Nouvelle scène projetée" class=center><div style=margin-top:1rem></div></p></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"></div><div class="col-md-6 btn-improve-page"><a href=https://github.com/clairelabitbonis/clairelabitbonis.github.io/edit/main/content/posts/teaching/3d_perception/monocular_localization/index.fr.md title="Améliorez cette page" target=_blank rel=noopener><i class="fas fa-code-branch"></i>Améliorez cette page</a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/fr/posts/introduction/ title=Introduction class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i>Précédent</div><div class=next-prev-text>Introduction</div></a></div><div class="col-md-6 next-article"><a href=/fr/posts/teaching/3d_perception/cc_segmentation/ title="Segmentation de nuages de points 3D par capteur à lumière structurée RGB-D avec CloudCompare" class="btn btn-outline-info"><div>Suivant <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>Segmentation de nuages de points 3D par capteur à lumière structurée RGB-D avec CloudCompare</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a><div class="dropdown languageSelector"><a class="btn dropdown-toggle" href=# id=languageSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="flag-icon flag-icon-fr"></span>Français</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/posts/teaching/3d_perception/monocular_localization><span class="flag-icon flag-icon-gb"></span>English</a></div></div></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">Table des matières</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#anchor-step-0>Définition des objectifs</a><ul><li><a href=#estimation-des-paramètres-extrinsèques>Estimation des paramètres extrinsèques</a></li><li><a href=#utilisation-du-programme>Utilisation du programme</a></li></ul></li><li><a href=#anchor-step-1><em><strong>Etape 1</strong></em> : afficher le modèle dans \(\mathcal{R_i}\)</a></li><li><a href=#anchor-step-2><em><strong>Etape 2</strong></em> : déterminer un critère d&rsquo;erreur</a></li><li><a href=#anchor-step-3><em><strong>Etape 3</strong></em> : Estimation des paramètres par la méthode des moindres carrés ordinaires</a></li><li><a href=#anchor-step-4><em><strong>Etape 4</strong></em> : projection de la pose estimée sur l&rsquo;image prise d&rsquo;un point de vue différent</a></li><li><a href=#bonus>Bonus pour la fin</a></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2022 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Alimenté par
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body);>renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"\\[",right:"\\]",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false}]});</script></body></html>