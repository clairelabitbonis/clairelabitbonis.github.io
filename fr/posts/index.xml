<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Claire Labit-Bonis</title><link>http://clairelabitbonis.github.io/fr/posts/</link><description>Recent content in Posts on Claire Labit-Bonis</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 04 Nov 2022 10:00:00 +0900</lastBuildDate><atom:link href="http://clairelabitbonis.github.io/fr/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>DLCV-CM-00 | De l'I.A. au deep learning</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/01_why_deep_learning/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/01_why_deep_learning/</guid><description> Objectifs pédagogiques Ce premier cours a pour objectif de répondre aux trois questions suivantes autour du deep learning :
à quoi ça sert ? pourquoi c&amp;rsquo;est techniquement intéressant ? quels en sont les grands principes ?</description></item><item><title>DLCV-CM-01 | Deep dive into object detection</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/02_lets_learn_deeply/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/course_dlcv/02_lets_learn_deeply/</guid><description/></item><item><title>DLCV-TP-00 | Présentation</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/00_presentation/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/00_presentation/</guid><description>Objectifs pédagogiques L&amp;rsquo;objectif de ces séances de travaux pratiques est de toucher à toutes les étapes de l&amp;rsquo;ingénierie du deep learning, à savoir :
l&amp;rsquo;acquisition et l&amp;rsquo;annotation de données, l&amp;rsquo;apprentissage de réseaux de convolution, l&amp;rsquo;évaluation des performances de la tâche apprise, la visualisation des résultats obtenus. Pour cela, notre point de départ sera le détecteur d&amp;rsquo;objets très largement connu et utilisé par les communautés scientifique mais aussi industrielle : YOLO (You Only Look Once).</description></item><item><title>DLCV-TP-01 | Le Bingo de YOLO !</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/02_yolo/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/02_yolo/</guid><description>Présentation L&amp;rsquo;objectif du TP du jour est d&amp;rsquo;utiliser le dataset construit la semaine dernière pour entrainer YOLOv5 à détecter les classes d&amp;rsquo;objets annotées. Voyez-le comme une grille de Bingo à remplir. Plus vous en validez, mieux c&amp;rsquo;est.
Attention, &amp;ldquo;la moulinette des labels&amp;rdquo; et &amp;ldquo;split, split, split&amp;rdquo; sont nécessaires pour lancer l&amp;rsquo;apprentissage en fin de séance. Considérez-les comme la quête principale. Si vous avez le temps, réalisez les quêtes annexes : &amp;ldquo;seeing data augmentation&amp;rdquo;, &amp;ldquo;et la valeur du poids est&amp;hellip;&amp;rdquo;, &amp;ldquo;detect with coco.</description></item><item><title>DLCV-TP-11 | Voyons...</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/03_lets_see/</link><pubDate>Fri, 04 Nov 2022 10:00:00 +0900</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/03_lets_see/</guid><description>Previously in &amp;ldquo;DLCV Practical sessions&amp;rdquo;&amp;hellip; Il est beau le dataset Répartition des classes Grâce à nous tou·te·s, on a construit un beau dataset qui nous permet de détecter plein de classes d&amp;rsquo;objets très utiles. Le tableau ci-dessous indique le nombre d&amp;rsquo;images et la répartition des différentes classes entre les ensembles de train, validation et test :
Analyse des labels La quantité de labels par image et leur forme varie en fonction des classes annotées.</description></item><item><title>3DP-TP-00 | Segmentation de nuages de points 3D par capteur à lumière structurée RGB-D avec CloudCompare</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/cc_segmentation/</link><pubDate>Sat, 16 Jul 2022 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/cc_segmentation/</guid><description>Contrôle qualité d&amp;rsquo;objets 3D.</description></item><item><title>3DP-TP-01 | Localisation monoculaire par PnL itérative</title><link>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/monocular_localization/</link><pubDate>Sat, 16 Jul 2022 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/teaching/3d_perception/practical_sessions_3d_perception/monocular_localization/</guid><description>Iterative estimation of a camera extrinsic parameters.</description></item><item><title>Introduction</title><link>http://clairelabitbonis.github.io/fr/posts/introduction/</link><pubDate>Mon, 08 Jun 2020 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/posts/introduction/</guid><description>La versionj en francais</description></item><item><title>Search Results</title><link>http://clairelabitbonis.github.io/fr/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>http://clairelabitbonis.github.io/fr/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item></channel></rss>