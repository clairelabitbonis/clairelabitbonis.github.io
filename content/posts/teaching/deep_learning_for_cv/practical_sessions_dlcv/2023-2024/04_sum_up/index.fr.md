---
title: "DLCV2.4 | On récapitule tout"
date: 2024-01-02T10:00:00+09:00
description: ""
summary: ""

draft: false
math: true 
highlight: true
hightlight_languages: ["python","bash"]

authors: ["Claire Labit-Bonis"]

hero: featured.png

tags: ["Teaching"]

menu:
  sidebar:
    name: "04 | On récapitule tout"
    identifier: dlcv-practical-sessions-2023-2024-04
    parent: dlcv-2023-2024-practical
    weight: 30
---

{{< alert type="success" >}}
Par souci de clarté, je récapitule tout ici (modalités d'évaluation, exécution des codes d'évaluation, etc.). Comme ça, pas besoin d'aller vous perdre dans les différents sujets.
{{< /alert >}}


## Et c'est pas fini... 

Bonjour, bonjour ! Une nouvelle année commence, et quoi de mieux pour commencer l'année qu'un peu d'analyse qualitative et quantitative de YOLO sur [notre super *dataset*](https://clairelabitbonis.github.io/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/03_lets_see/#il-est-tres-beau-le-dataset) ? 

L'évaluation de la matière *deep learning* sera basée sur une capsule vidéo d'environ 10 minutes par binôme. 

{{< footnote >}}
ça veut dire que 9 minutes c'est OK, 11 minutes c'est OK, mais 3 minutes c'est trop court et 45 minutes c'est trop long. Et ça veut aussi dire que les deux membres du binôme doivent être perceptibles dans la vidéo (qu'on puisse vous voir ou vous entendre, selon si vous vous filmez ou non).
{{< /footnote >}}




