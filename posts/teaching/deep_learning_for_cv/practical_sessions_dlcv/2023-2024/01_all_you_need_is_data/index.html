<!doctype html><html><head><title>DLCV2.1 | All you need is data</title>
<meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0a17c6d8ab77c1c9df3e22d1e0f9b13d_86416_42x0_resize_box_3.png><meta property="og:title" content="DLCV2.1 | All you need is data"><meta property="og:description" content="Ce sujet est déjà dépassé : je rédige le sujet de la séance du jour en fonction de ce qui s&rsquo;est passé à la précédente. Donc il y a des trucs ici qui ne sont plus valides. Tout ce dont vous avez besoin pour entrainer un détecteur d&rsquo;objets est d&rsquo;avoir des données qui représentent ces objets. Et de les nettoyer (les données, pas les objets). Et de les trier. Et de les annoter."><meta property="og:type" content="article"><meta property="og:url" content="http://clairelabitbonis.github.io/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/01_all_you_need_is_data/"><meta property="og:image" content="http://clairelabitbonis.github.io/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/01_all_you_need_is_data/featured.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-12-05T10:00:00+09:00"><meta property="article:modified_time" content="2023-12-05T10:00:00+09:00"><meta name=description content="DLCV2.1 | All you need is data"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span>
</button>
<a class=navbar-brand href=/><img src=/images/site/main-logo_hu0a17c6d8ab77c1c9df3e22d1e0f9b13d_86416_42x0_resize_box_3.png alt=Logo>
Claire Labit-Bonis</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20>
</a><a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20>
</a><a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu0a17c6d8ab77c1c9df3e22d1e0f9b13d_86416_42x0_resize_box_3.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu2230ff0c1688347dd01f9a568f627fa9_80011_42x0_resize_box_3.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Chercher data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts data-filter=all>Articles</a></li><div class=subtree><li><i class="fas fa-minus-circle"></i><a class=active href=/posts/teaching/>Enseignements</a><ul class=active><li><i class="fas fa-plus-circle"></i><a href=/posts/teaching/3d_perception/>Perception 3D</a><ul><li><i class="fas fa-plus-circle"></i><a href=/posts/teaching/3d_perception/practical_sessions_3d_perception/>Travaux pratiques</a><ul><li><a href=/posts/teaching/3d_perception/practical_sessions_3d_perception/cc_segmentation/ title=Segmentation>Segmentation</a></li><li><a href=/posts/teaching/3d_perception/practical_sessions_3d_perception/monocular_localization/ title="Localisation mono.">Localisation mono.</a></li></ul></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/posts/teaching/deep_learning_for_cv/>Deep Learning & CV</a><ul class=active><li><i class="fas fa-plus-circle"></i><a href=/posts/teaching/deep_learning_for_cv/course_dlcv/>Cours</a><ul><li><a href=/posts/teaching/deep_learning_for_cv/course_dlcv/01_why_deep_learning/ title="00 | De l'IA au DL">00 | De l'IA au DL</a></li><li><a href=/posts/teaching/deep_learning_for_cv/course_dlcv/02_lets_learn_deeply/ title="01 | DD into OD">01 | DD into OD</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/>Travaux pratiques</a><ul class=active><li><i class="fas fa-plus-circle"></i><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2022-2023/>2022-2023</a><ul><li><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2022-2023/00_presentation/ title="00 | Présentation">00 | Présentation</a></li><li><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2022-2023/02_yolo/ title="01 | YOLO !">01 | YOLO !</a></li><li><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2022-2023/03_lets_see/ title="10 | Voyons...">10 | Voyons...</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/>2023-2024</a><ul class=active><li><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/00_presentation/ title="00 | Présentation">00 | Présentation</a></li><li><a class=active href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/01_all_you_need_is_data/ title="01 | All you need is data">01 | All you need is data</a></li><li><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/02_yolo/ title="02 | YOLO !">02 | YOLO !</a></li><li><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/03_lets_see/ title="03 | Tadaaaam !">03 | Tadaaaam !</a></li><li><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/04_sum_up/ title="04 | On récapitule tout">04 | On récapitule tout</a></li></ul></li></ul></li></ul></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/01_all_you_need_is_data/featured.png)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/claire_hufa4d5753e97ed9e5e63c04dfec44ec48_673603_120x120_fit_q75_box.jpg alt="Author Image"><h5 class=author-name>Claire Labit-Bonis</h5><p>mardi 5 décembre 2023</p></div><div class=title><h1>DLCV2.1 | All you need is data</h1></div><div class=post-content id=post-content><div class="alert alert-danger"><strong>Ce sujet est déjà dépassé : je rédige le sujet de la séance du jour en fonction de ce qui s&rsquo;est passé à la précédente. Donc il y a des trucs ici qui ne sont plus valides.</strong></div><div class="alert alert-success"><strong>Tout ce dont vous avez besoin pour entrainer un détecteur d&rsquo;objets est d&rsquo;avoir des données qui représentent ces objets. Et de les nettoyer (les données, pas les objets). Et de les trier. Et de les annoter. Et d&rsquo;en jeter un peu parce qu&rsquo;elles sont pas si bien. Et d&rsquo;en rajouter encore parce qu&rsquo;il y en a plus assez. Etc. &#x1f44d;</strong></div><div class="alert alert-danger"><strong>ATTENTION : vous devez avoir déposé vos données et votre <em>split</em> <code>train/val/test.txt</code> sur le serveur GPU avant la fin de la séance. On (l&rsquo;équipe) lancera l&rsquo;ensemble des configurations d&rsquo;apprentissage d&rsquo;ici la semaine prochaine. Pas de données, pas d&rsquo;apprentissage. Pas d&rsquo;apprentissage, pas de TP. Pas de TP, pas de TP (les réfs à Mission Cléopâtre commencent à dater&mldr;).</strong></div><h2 id=acquisition>Acquisition</h2><p>Prenez 5 vidéos de 10 secondes dans lesquelles se trouve la classe que vous voulez apprendre à détecter.</p><p>Posez-vous des questions :</p><ul><li>est-ce que l&rsquo;objet peut dépasser du cadre ?</li><li>est-ce que j&rsquo;ai suffisamment d&rsquo;objets différents de la même classe ?</li><li>est-ce que le contexte change entre les séquences ?</li><li>etc.</li></ul><p>Faites attention à ce que des objets appartenant aux classes des autres binômes ne se retrouvent pas dans vos séquences, sinon <strong><em>vous devrez les annoter aussi.</em></strong></p><p>Créez sur votre session une arborescence de fichiers comme la suivante :</p><center><p><img src=images/arborescence.png alt="Arborescence de fichiers"></p></center><p>&mldr;dans laquelle il faut :</p><ul><li>remplacer <code>nom_de_classe</code> par le nom de la classe que vous annotez ;</li><li>remplacer <code>noms_du_binome1</code> par vos noms de famille ;</li><li>les dossiers 1 à 5 correspondent aux séquences 1 à 5.</li></ul><p>Une fois acquises, copiez les vidéos sur votre PC et extrayez-en les <em>frames</em> avec <code>ffmpeg</code> dans les différents dossiers <code>images</code> :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ffmpeg -i &lt;video.mp4&gt; -vf fps<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span> -start_number <span style=color:#ae81ff>0</span> &lt;nom_de_classe&gt;/&lt;noms_du_binome&gt;/&lt;num_sequence&gt;/images/frame_%06d.jpg
</span></span></code></pre></div><p>Vous devez avoir une arborescence qui ressemble à ça à la fin :</p><center><p><img src=images/arborescence_extract_images.png alt="Arborescence de fichiers"></p></center><h2 id=import-des-données-dans-cvat>Import des données dans CVAT</h2><p>C&rsquo;est là que le travail commence&mldr; Connectez-vous avec vos identifiants INSA au serveur d&rsquo;annotation <a href=https://cvat.ens.insa-toulouse.fr/>CVAT</a>.</p><p>Pour chaque séquence vidéo, créez une nouvelle tâche :</p><center><p><img src=images/cvat_create_task.png alt="Nouvelle tâche"></p></center><p>Renseignez le nom de la tâche (par exemple <code>&lt;nom-classe>_&lt;numero-sequence></code>) et ajoutez le label de la classe que vous annotez :</p><center><p><img src=images/cvat_create_task_settings.png alt="Nouvelle tâche - Settings"></p></center><p>Ajoutez ensuite (par <em>drag and drop</em>) toutes les <code>frame_XXXXXX.jpg</code> de la séquence en question et finissez par sélectionner le format d&rsquo;annotation <code>YOLO 1.1</code> dans l&rsquo;<code>Advanced Configuration</code>, avant de <code>Submit & Open</code>.</p><p>L&rsquo;interface de labellisation s&rsquo;ouvre.</p><h2 id=labellisation>Labellisation</h2><p>Dans la barre d&rsquo;outils à gauche, pour créer une nouvelle annotation :</p><ul><li>sélectionnez <code>Draw new rectangle</code>,</li><li>la classe que vous voulez annoter,</li><li><code>By 2 points</code> (il faudra cliquer les coins haut-gauche et bas-droite pour tracer un rectangle),</li><li>et <code>Track</code> (la <em>bounding box</em> sera propagée aux <em>frames</em> suivantes et gardera la même identité. Très pratique si vous ne voulez pas réannoter tous les objets à chaque <em>frame</em>&mldr;)</li></ul><center><p><img src=images/interface_labellisation.png alt="Labellisation - interface"></p></center><blockquote><p><strong>Cheatsheet :</strong></p><ul><li><code>F</code> : avance d&rsquo;une <em>frame</em></li><li><code>D</code> : recule d&rsquo;une <em>frame</em></li><li><code>V</code> : saute plusieurs <em>frames</em> en avant <strong>et fait une interpolation linéaire pour propager les labels intermédiaires</strong></li><li><code>C</code> : saute plusieurs <em>frames</em> en arrière <strong>et fait une interpolation linéaire pour propager les labels intermédiaires</strong></li><li><code>N</code> : crée une nouvelle annotation du même type que la précédente (<code>Track rectangle by 2 points</code> par exemple)</li></ul></blockquote><p>Les options disponibles pour chaque cible vous permettent de :</p><ul><li>les rendre visible/invisible (ça ne les supprime pas, c&rsquo;est juste pour éviter de se faire gêner par des annotations existantes),</li><li>les indiquer comme &ldquo;sorties du cadre&rdquo;,</li><li>les marquer &ldquo;occultées&rdquo; quand une autre cible passe devant ou que l&rsquo;objet passe derrière quelque chose (quand il est occulté, quoi),</li><li>régler l&rsquo;opacité de la boite, et d&rsquo;autres attributs d&rsquo;aspect.</li></ul><h2 id=export-du-dataset>Export du <em>dataset</em></h2><div class="alert alert-danger"><strong>Quand vous aurez fini d&rsquo;annoter toutes vos séquences, dites-le nous. Nous devons ajouter vos tâches à un projet CVAT global qui contient toutes les classes d&rsquo;objets, de manière à ce que quand vous exporterez vos labellisations, les numéros de classes soient bons. Sinon, par défaut ils sont tous à zéro. Et YOLO apprendra que la classe <code>papillons</code> et la classe <code>playmobil</code> sont la même chose puisqu&rsquo;elles ont toutes les deux le numéro <code>0</code>.</strong></div><p>Une fois qu&rsquo;on vous donne le feu vert, vous pouvez exporter chacune de vos tâches (<code>Tasks > Actions > Export task dataset</code>). Choisissez le format <code>YOLO 1.1</code>, ne sauvegardez pas les images, donnez le nom que vous voulez à l&rsquo;export et validez.</p><center><p><img src=images/export.png alt=Export>
<img src=images/export_txt.png alt="Export - fichiers texte"></p></center><p>Vous obtenez un <code>.zip</code> qui contient un fichier <code>.txt</code> par image, dans <code>obj_train_data</code>. Vous pouvez copier ces fichiers dans le dossier <code>labels</code> de la séquence que vous venez d&rsquo;exporter :</p><center><p><img src=images/arborescence_images_labels.png alt="Export - copie labels"></p></center><h2 id=séparation-trainvaltest>Séparation train/val/test</h2><p>On y est presque. Il ne reste plus qu&rsquo;à séparer vos séquences en trois sous-ensembles qui serviront à l&rsquo;apprentissage, à la validation et au test. Vous devez créer trois fichiers : <code>train.txt</code>, <code>val.txt</code> et <code>test.txt</code>. Dans chacun, vous mettrez la liste des chemins d&rsquo;accès vers les images selon qu&rsquo;elles doivent aller en base d&rsquo;apprentissage, de validation ou de test. Par exemple, dans <code>train.txt</code> :</p><pre><code>./velo/tic_et_tac/4/images/frame_000002.jpg
./velo/tic_et_tac/4/images/frame_000118.jpg
...
./velo/tic_et_tac/2/images/frame_000004.jpg
./velo/tic_et_tac/1/images/frame_000001.jpg
./velo/tic_et_tac/3/images/frame_000256.jpg
</code></pre><div class="alert alert-danger"><strong><p>La répartition de vos données entre les différentes bases est une étape cruciale :</p><ul><li>allez-vous mettre 3 séquences complètes en <code>train</code>, une en <code>val</code> et une en <code>test</code>, au risque d&rsquo;avoir des exemples en test qui sont trop éloignés de ceux de la base d&rsquo;apprentissage ?</li><li>ou bien allez-vous plutôt mettre les débuts de séquence en <code>train</code>, les milieux en <code>val</code>, les fins en <code>test</code>, mais dans ce cas vous biaiserez complètement l&rsquo;apprentissage et obtiendrez des performances étrangement un peu trop hautes ?</li><li>vous pouvez aussi choisir la méthode bourrine et faire un random total sur la répartition&mldr;</li></ul></strong></div><h2 id=copie-sur-le-serveur-gpu-2>Copie sur le serveur GPU 2</h2><p>Une fois votre répartition faite, sauvegardez les trois fichiers à la racine de votre dossier <code>&lt;noms_binome></code>, et copiez le tout avec :</p><pre tabindex=0><code>cd &lt;nom_de_classe&gt;/..
scp &lt;noms_du_binome&gt; srv-gei-gpu2:/scratch/labi/DLCV/2023-2024/dataset/&lt;nom_de_classe&gt;/
</code></pre><center><p><img src=images/split.png alt="Dossier final"></p></center><p>Dernière chose : donnez-nous les droits sur les dossiers que vous créez. En vous connectant en SSH à <code>srv-gei-gpu2</code> et en faisant un <code>chmod -R 777</code> sur votre dossier dans <code>/scratch/labi/DLCV/2023-2024/dataset/&lt;nom_de_classe>/</code>, par exemple.</p></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"></div><div class="col-md-6 btn-improve-page"><a href=https://github.com/clairelabitbonis/clairelabitbonis.github.io/edit/main/content/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/01_all_you_need_is_data/index.fr.md title="Améliorez cette page" target=_blank rel=noopener><i class="fas fa-code-branch"></i>
Améliorez cette page</a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/00_presentation/ title="DLCV 2ème édition | Présentation" class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i> Précédent</div><div class=next-prev-text>DLCV 2ème édition | Présentation</div></a></div><div class="col-md-6 next-article"><a href=/posts/teaching/deep_learning_for_cv/practical_sessions_dlcv/2023-2024/02_yolo/ title="DLCV2.2 | Le Bingo de YOLO !" class="btn btn-outline-info"><div>Suivant <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>DLCV2.2 | Le Bingo de YOLO !</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">Table des matières</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#acquisition>Acquisition</a></li><li><a href=#import-des-données-dans-cvat>Import des données dans CVAT</a></li><li><a href=#labellisation>Labellisation</a></li><li><a href=#export-du-dataset>Export du <em>dataset</em></a></li><li><a href=#séparation-trainvaltest>Séparation train/val/test</a></li><li><a href=#copie-sur-le-serveur-gpu-2>Copie sur le serveur GPU 2</a></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=http://clairelabitbonis.github.io/#about>A propos</a></li><li class=nav-item><a class=smooth-scroll href=http://clairelabitbonis.github.io/#publications>Publications</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contactez moi :</h5><ul><li><a href=mailto:clairelabitbonis@gmail.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>clairelabitbonis@gmail.com</span></a></li></ul></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_3.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2022 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Alimenté par
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad()</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)>renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})</script><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>